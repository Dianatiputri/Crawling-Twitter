{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('labeling.csv', sep=';')\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#konversi label ke polaritas\n",
    "def convert(polarity):\n",
    "    if polarity == 'positif':\n",
    "        return 1\n",
    "    elif polarity == 'netral':\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Polarity'] = df['label'].apply(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['STOP_REMOVAL']\n",
    "y = df['Polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1545,)\n",
      "Shape of Sparse Matrix:  (1545, 2542)\n",
      "Amount of Non-Zero occurrences:  16393\n"
     ]
    }
   ],
   "source": [
    "#vectorizer = CountVectorizer()\n",
    "#X = vectorizer.fit_transform(df['isi'])\n",
    "\n",
    "bow_transformer = CountVectorizer()\n",
    "print(df['STOP_REMOVAL'].shape)\n",
    "X = bow_transformer.fit_transform(df['STOP_REMOVAL'])\n",
    "\n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "# file = open('response.txt', 'w')\n",
    "# file.write(str(np.array((X[0]))))\n",
    "# file.close()\n",
    "\n",
    "#word_list = bow_transformer.get_feature_names();    \n",
    "#count_list = X.toarray().sum(axis=0)\n",
    "# print('word_list = ', word_list)\n",
    "# print('count_list = ', count_list)\n",
    "\n",
    "#dict_count_word = dict(zip(word_list,count_list))\n",
    "#sorted_dict_count_word = sorted(dict_count_word.items(), key=lambda kv: kv[1], reverse = True)[:5]\n",
    "#print('sorted_dict_count_word = ', sorted_dict_count_word)\n",
    "\n",
    "# print(X.toarray())\n",
    "print('Shape of Sparse Matrix: ', X.shape)\n",
    "print('Amount of Non-Zero occurrences: ', X.nnz)\n",
    "\n",
    "# save the Count Vectorized to disk\n",
    "filename1 = 'count_vectorized1.pkl'\n",
    "pickle.dump(bow_transformer, open(filename1, 'wb'))\n",
    "\n",
    "#TFID Transform\n",
    "tf_transform = TfidfTransformer(use_idf=False).fit(X)\n",
    "X = tf_transform.transform(X)\n",
    "#print(X.shape)\n",
    "#print(X)\n",
    "\n",
    "# save the TFID to disk\n",
    "filename1 = 'tfid_transform1.pkl'\n",
    "pickle.dump(tf_transform, open(filename1, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density: 0.4174018877677032\n"
     ]
    }
   ],
   "source": [
    "density = (100.0 * X.nnz / (X.shape[0] * X.shape[1]))\n",
    "print('Density: {}'.format((density)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2)\n",
    "# print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    }
   ],
   "source": [
    "#classifier data\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "print(nb)\n",
    "\n",
    "preds = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.86      0.80       158\n",
      "           0       0.79      0.70      0.74       140\n",
      "           1       0.50      0.09      0.15        11\n",
      "\n",
      "    accuracy                           0.76       309\n",
      "   macro avg       0.68      0.55      0.56       309\n",
      "weighted avg       0.76      0.76      0.75       309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "classification = classification_report(y_test, preds)\n",
    "s = StringIO(classification)\n",
    "with open('classification.csv', 'w') as f:\n",
    "    for line in s:\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7605177993527508\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, preds)\n",
    "a = np.asarray([accuracy])\n",
    "np.savetxt(\"accuracy.csv\", a, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final = df[['tanggal', 'user_name', 'author', 'isi', 'STOP_REMOVAL','label', 'Polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final = Final.rename(columns={'tanggal':'Tanggal', 'user_name':'User', 'author':'Author', 'isi':'Isi', 'STOP_REMOVAL':'Stop_Removal', 'label':'Label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final.to_csv('hasil_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model on training set\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'model_analisis.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7119741100323624\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1, -1, -1,  0, -1, -1,  0, -1, -1, -1, -1, -1,  0,  0,  0, -1,\n",
       "       -1,  1,  0, -1, -1, -1, -1,  0,  0, -1, -1, -1, -1,  0,  0,  0,  0,\n",
       "       -1, -1,  0,  0, -1, -1,  0, -1, -1,  0, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1,  1,  1,  1,  1,  0,  0, -1, -1, -1,  0,  0,  0, -1, -1, -1,\n",
       "       -1,  0, -1, -1, -1, -1, -1,  0, -1, -1,  0, -1,  0, -1, -1, -1, -1,\n",
       "        0, -1, -1,  0,  0, -1, -1, -1, -1, -1, -1,  0, -1,  0, -1, -1,  0,\n",
       "       -1, -1, -1, -1,  0, -1,  0, -1, -1, -1, -1, -1, -1,  0,  0,  0, -1,\n",
       "        0, -1, -1, -1, -1, -1,  0, -1,  0,  0, -1, -1,  0, -1,  0,  0, -1,\n",
       "        0,  0, -1,  0,  0,  0,  0,  0, -1, -1,  0, -1, -1, -1,  0,  0, -1,\n",
       "       -1,  0, -1, -1,  0, -1, -1,  0,  0, -1,  0, -1, -1,  0, -1, -1, -1,\n",
       "        0,  0,  0, -1,  0,  0,  0,  0,  0, -1,  0, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1,  1,  0, -1, -1,  0, -1, -1, -1, -1, -1, -1,  0,  0, -1,\n",
       "       -1, -1, -1, -1,  0, -1,  0, -1, -1,  1,  0,  0,  0, -1,  0,  0, -1,\n",
       "        0, -1, -1, -1,  0, -1, -1,  1,  0,  0, -1,  0, -1, -1, -1, -1,  0,\n",
       "        0,  0, -1,  0,  0, -1, -1, -1,  0,  0, -1, -1,  0, -1, -1, -1, -1,\n",
       "       -1, -1,  0, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0, -1,  0,  0, -1,\n",
       "       -1,  0, -1,  0,  0,  0,  0,  0,  0, -1, -1, -1, -1, -1, -1,  0,  0,\n",
       "       -1, -1, -1, -1,  0,  0,  0,  0, -1, -1, -1,  0,  0,  0, -1, -1, -1,\n",
       "        0,  0,  0], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
